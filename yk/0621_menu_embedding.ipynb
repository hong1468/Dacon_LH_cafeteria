{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/구내식당 식수인원/train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/구내식당 식수인원/test.csv')\n",
    "submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/구내식당 식수인원/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic text preprocessing\n",
    "\n",
    "def split_process(x, q):\n",
    "    x_ = []\n",
    "    x = x.split(' ')\n",
    "    for i in x:\n",
    "        if '(' in i and ':' in i and ')' in i:\n",
    "            continue\n",
    "        if '/' in i:\n",
    "            x_.extend(i.split('/'))\n",
    "        else:\n",
    "            x_.append(i)\n",
    "    x_ = list(set(x_))\n",
    "    x_.remove('')\n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_combinations = []\n",
    "for i in ['조식메뉴', '중식메뉴', '석식메뉴']:\n",
    "    food_combinations += train[i].apply(lambda x: split_process(x, i)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER PARAMETERS\n",
    "\n",
    "class CFG:\n",
    "    emb_dim = 200\n",
    "\n",
    "args = CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load w2v model\n",
    "\n",
    "TRAIN_W2V = True\n",
    "try:\n",
    "    model = Word2Vec.load('/content/drive/MyDrive/Colab Notebooks/구내식당 식수인원/food_embedding.model')\n",
    "    print(\"Model loaded\")\n",
    "except:\n",
    "    if TRAIN_W2V:\n",
    "        print(\"Training w2v\")\n",
    "        model = Word2Vec(sentences=food_combinations, size=args.emb_dim, window=7, min_count=0, workers=4, sg=0)\n",
    "        model.save('/content/drive/MyDrive/Colab Notebooks/구내식당 식수인원/food_embedding.model')\n",
    "    else:\n",
    "        print(\"Model loading failed. Do not train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v demo\n",
    "model.wv.most_similar('된장찌개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(df):\n",
    "    df['일자'] = pd.to_datetime(df['일자'], format=\"%Y-%m-%d\")\n",
    "    df['year'] = df['일자'].dt.year\n",
    "    df['month'] = df['일자'].dt.month\n",
    "    df['day'] = df['일자'].dt.day\n",
    "    df = df.drop('일자', axis=1)\n",
    "    return df\n",
    "\n",
    "def get_food_embedding(x):\n",
    "    x_ = []\n",
    "    x = x.split(' ')\n",
    "    for i in x:\n",
    "        if '(' in i and ':' in i and ')' in i:\n",
    "            continue\n",
    "        if '/' in i:\n",
    "            x_.extend(i.split('/'))\n",
    "        else:\n",
    "            x_.append(i)\n",
    "    x_ = list(set(x_))\n",
    "    x_.remove('')\n",
    "    vec_ = np.zeros(args.emb_dim)\n",
    "    for i in x_:\n",
    "        vec = model.wv.get_vector(i)\n",
    "        vec_ += vec\n",
    "    vec_ /= len(x_)\n",
    "    return vec_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General preprocessing\n",
    "df_train = process_date(train)\n",
    "day_encoder = LabelEncoder()\n",
    "df_train['요일'] = day_encoder.fit_transform(df_train['요일'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embedding\n",
    "df_train['조식메뉴_embedding'] = df_train['조식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "df_train['중식메뉴_embedding'] = df_train['중식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "df_train['석식메뉴_embedding'] = df_train['석식메뉴'].apply(lambda x: get_food_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lunch = df_train['중식계']\n",
    "y_dinner = df_train['석식계']\n",
    "df_train.drop(['조식메뉴', '중식메뉴', '석식메뉴', '중식계', '석식계'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_common = df_train.iloc[:, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_arr_lunch = np.array(df_train.iloc[:, 10].to_numpy().tolist()) # Ver 2\n",
    "emb_arr_dinner = np.array(df_train.iloc[:, 11].to_numpy().tolist()) # Ver 2\n",
    "\n",
    "X_train_lunch = np.concatenate((X_common.to_numpy(), emb_arr_lunch), axis=1)\n",
    "X_train_dinner = np.concatenate((X_common.to_numpy(), emb_arr_dinner), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lunch, X_test_lunch, y_train_lunch, y_test_lunch = train_test_split(X_train_lunch, y_lunch, test_size=0.1, random_state=42)\n",
    "X_train_dinner, X_test_dinner, y_train_dinner, y_test_dinner = train_test_split(X_train_dinner, y_dinner, test_size=0.1, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
